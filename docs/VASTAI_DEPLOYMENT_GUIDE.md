# Vast.ai ë³‘ë ¬ ì‹¤í–‰ ê°€ì´ë“œ
Pareto Frontier ì‹¤í—˜ì„ 4ê°œì˜ Vast.ai ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ëŠ” ë°©ë²•

**ì‘ì„±ì¼**: 2025-11-02
**ì˜ˆìƒ ì‹œê°„**: 35-70ì‹œê°„ (ë³‘ë ¬ ì‹¤í–‰)
**ì˜ˆìƒ ë¹„ìš©**: $60-100 (RTX 3090/4090 ê¸°ì¤€)

---

## ğŸ“‹ ëª©ì°¨
1. [ì‚¬ì „ ì¤€ë¹„](#1-ì‚¬ì „-ì¤€ë¹„)
2. [Vast.ai ì¸ìŠ¤í„´ìŠ¤ ì„¤ì •](#2-vastai-ì¸ìŠ¤í„´ìŠ¤-ì„¤ì •)
3. [ê° ì‹¤í—˜ ì‹¤í–‰](#3-ê°-ì‹¤í—˜-ì‹¤í–‰)
4. [ëª¨ë‹ˆí„°ë§](#4-ëª¨ë‹ˆí„°ë§)
5. [ê²°ê³¼ ìˆ˜ì§‘](#5-ê²°ê³¼-ìˆ˜ì§‘)
6. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#6-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## 1. ì‚¬ì „ ì¤€ë¹„

### 1.1 GitHubì— ì½”ë“œ í‘¸ì‹œ

```bash
cd C:\Users\Ramster\Documents\Files\SKKU\Project\DNN_channel_estimation_training
git add .
git commit -m "Pareto experiments ready for Vast.ai"
git push origin main
```

**GitHub ë ˆí¬ì§€í† ë¦¬ URL ë³µì‚¬** (ë‚˜ì¤‘ì— ì‚¬ìš©)

### 1.2 ë°ì´í„°ì…‹ ì¤€ë¹„

í•„ìš”í•œ íŒŒì¼:
- `saved_model/Large_estimator_v3_base_extended_final.pt` (~1.7GB)
- `saved_model/Large_estimator_v4_base_extended_final.pt` (~1.7GB)
- `dataset/PDP_processed/` í´ë”

**ì˜µì…˜ A: Google Drive (ì¶”ì²œ)**

1. Google Driveì— í´ë” ìƒì„±
2. íŒŒì¼ ì—…ë¡œë“œ
3. ê³µìœ  ë§í¬ ìƒì„± (ëˆ„êµ¬ë‚˜ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥)
4. íŒŒì¼ ID ì¶”ì¶œ:
   ```
   https://drive.google.com/file/d/FILE_ID_HERE/view?usp=sharing
   ```

**ì˜µì…˜ B: Vast.ai ìŠ¤í† ë¦¬ì§€**
- Vast.ai ê³„ì •ì— ì§ì ‘ ì—…ë¡œë“œ (ë¹ ë¥´ì§€ë§Œ ë¹„ìŒˆ)

**ì˜µì…˜ C: SCP ì§ì ‘ ì „ì†¡**
- ê° ì¸ìŠ¤í„´ìŠ¤ì— ê°œë³„ ì—…ë¡œë“œ (ì‹œê°„ ì†Œìš”)

### 1.3 WandB API Key (ì„ íƒ)

```bash
# WandB ë¡œê·¸ì¸ í›„
wandb login --relogin
# API key ë³µì‚¬
```

---

## 2. Vast.ai ì¸ìŠ¤í„´ìŠ¤ ì„¤ì •

### 2.1 ì¸ìŠ¤í„´ìŠ¤ ìŠ¤í™ ì„ íƒ

**ì¶”ì²œ GPU:**
- RTX 3090 (24GB VRAM): ~$0.3/hour
- RTX 4090 (24GB VRAM): ~$0.5/hour

**ì¶”ì²œ ì„¤ì •:**
- **Image**: `pytorch/pytorch:2.0.1-cuda11.7-cudnn8-runtime`
- **Disk**: 100GB+
- **RAM**: 32GB+
- **Upload Speed**: 100Mbps+ (ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì†ë„)

**ì™œ Docker ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ë§Œë“¤ì§€ ì•Šë‚˜?**
- Vast.aiëŠ” ì´ë¯¸ Docker ê¸°ë°˜ìœ¼ë¡œ ì‹¤í–‰ë¨
- PyTorch ì´ë¯¸ì§€ì— ëª¨ë“  ê²ƒì´ í¬í•¨ë¨
- ì¶”ê°€ íŒ¨í‚¤ì§€ëŠ” `pip install`ë¡œ ì„¤ì¹˜
- ì§ì ‘ Docker ë§Œë“¤ë©´ ë¹Œë“œ ì‹œê°„ ë‚­ë¹„ + ë³µì¡ë„ ì¦ê°€

### 2.2 ì¸ìŠ¤í„´ìŠ¤ 4ê°œ ìƒì„±

ê° ì‹¤í—˜ë§ˆë‹¤ í•˜ë‚˜ì”©:
1. **Instance 1**: Prompt (15 runs, ~30-60h)
2. **Instance 2**: LoRA (20 runs, ~40-80h)
3. **Instance 3**: Hybrid (15 runs, ~30-60h)
4. **Instance 4**: Adapter (20 runs, ~40-80h)

**ì¸ìŠ¤í„´ìŠ¤ ì´ë¦„ ì„¤ì •:**
- `pareto-prompt`
- `pareto-lora`
- `pareto-hybrid`
- `pareto-adapter`

---

## 3. ê° ì‹¤í—˜ ì‹¤í–‰

### 3.1 ê¸°ë³¸ Setup (4ê°œ ì¸ìŠ¤í„´ìŠ¤ ëª¨ë‘ ë™ì¼)

**Step 1: SSH ì ‘ì†**
```bash
ssh root@X.X.X.X -p XXXXX
```

**Step 2: ì½”ë“œ í´ë¡ **
```bash
cd /workspace
git clone https://github.com/YOUR_USERNAME/YOUR_REPO DNN_channel_estimation_training
cd DNN_channel_estimation_training
```

**Step 3: ì˜ì¡´ì„± ì„¤ì¹˜**
```bash
# Vast.aiìš© ê°„ì†Œí™”ëœ requirements ì‚¬ìš© (ì¤‘ìš”!)
pip install -r requirements_vastai.txt

# ë˜ëŠ” ìˆ˜ë™ ì„¤ì¹˜
pip install transformers peft wandb einops pyyaml scipy h5py gdown torch-tensorrt
```

**ì£¼ì˜**: `requirements.txt`ëŠ” Windows í™˜ê²½ìš©ì´ë¯€ë¡œ Vast.ai(Linux)ì—ì„œëŠ” `requirements_vastai.txt` ì‚¬ìš©!

**Step 4: CUDA í™•ì¸**
```bash
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}'); print(f'Device: {torch.cuda.get_device_name(0)}')"
```

**Step 5: ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ**

**ë°©ë²• 1: ë¡œì»¬ì—ì„œ ì••ì¶• í›„ Jupyter Lab ì—…ë¡œë“œ (ê°•ë ¥ ì¶”ì²œ!)**

Google Drive gdownì´ ê¶Œí•œ ë¬¸ì œë¡œ ì‹¤íŒ¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì§ì ‘ ì—…ë¡œë“œê°€ ê°€ì¥ í™•ì‹¤í•©ë‹ˆë‹¤.

*ë¡œì»¬ ì»´í“¨í„° (Windows PowerShell):*
```powershell
cd C:\Users\YOUR_PATH\DNN_channel_estimation_training

# ì••ì¶•
Compress-Archive -Path dataset -DestinationPath dataset.zip -Force
Compress-Archive -Path saved_model -DestinationPath saved_model.zip -Force
```

*Vast.ai Jupyter Labì—ì„œ:*
1. Jupyter Terminal â†’ Launch Application
2. ì¢Œì¸¡ íŒŒì¼ ë¸Œë¼ìš°ì €
3. Upload ë²„íŠ¼ (â†‘) í´ë¦­
4. `dataset.zip`, `saved_model.zip` ì„ íƒ
5. ì—…ë¡œë“œ ëŒ€ê¸° (10-30ë¶„)

*Vast.ai í„°ë¯¸ë„ì—ì„œ ì••ì¶• í•´ì œ:*
```bash
cd /workspace/DNN_channel_estimation_training
unzip dataset.zip
unzip saved_model.zip

# í™•ì¸
ls dataset/PDP_processed/*.mat | head -5
ls saved_model/Large_estimator_v3_base_final.pt
ls saved_model/Large_estimator_v4_base_final.pt
```

**ë°©ë²• 2: Google Drive (gdown) - ê¶Œí•œ ë¬¸ì œ ê°€ëŠ¥**

```bash
# Google Drive í´ë” ë‹¤ìš´ë¡œë“œ
gdown --folder https://drive.google.com/drive/folders/YOUR_FOLDER_ID

# ì‹¤íŒ¨ ì‹œ wgetìœ¼ë¡œ ê°œë³„ íŒŒì¼
wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=FILE_ID' -O file.zip
unzip file.zip
```

**ì£¼ì˜**: Google Drive ê³µìœ  ì„¤ì •ì„ "ë§í¬ê°€ ìˆëŠ” ëª¨ë“  ì‚¬ìš©ì"ë¡œ ë³€ê²½í•´ë„ gdownì´ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. **ë°©ë²• 1 ì¶”ì²œ!**

**Step 6: WandB ë¡œê·¸ì¸ (ì„ íƒ)**
```bash
wandb login YOUR_API_KEY
```

### 3.2 ì‹¤í—˜ë³„ ì‹¤í–‰ ëª…ë ¹

**ì¶”ì²œ ë°©ë²•: nohup ì‚¬ìš© (tmuxë³´ë‹¤ ê°„ë‹¨)**

**Instance 1: Adapter**
```bash
cd /workspace/2025IEEEOJCOMS

# ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
nohup python Transfer_Pareto_Adapter.py > adapter.log 2>&1 &

# ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸
tail -f adapter.log

# GPU ì‚¬ìš©ë¥  í™•ì¸
watch -n 1 nvidia-smi

# Ctrl+Cë¡œ ë¡œê·¸ í™•ì¸ ì¤‘ë‹¨ (ì‹¤í—˜ì€ ê³„ì† ì‹¤í–‰ë¨)
```

**ëŒ€ì•ˆ: tmux ì‚¬ìš©**
```bash
# tmux ì„¸ì…˜ ìƒì„± (ì—°ê²° ëŠê²¨ë„ ê³„ì† ì‹¤í–‰)
tmux new -s adapter

# ì‹¤í–‰
python Transfer_Pareto_Adapter.py

# Ctrl+B, Dë¡œ detach (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)
```

**Instance 2: LoRA**
```bash
tmux new -s lora
python Transfer_Pareto_LoRA.py
# Ctrl+B, D
```

**Instance 3: Hybrid**
```bash
tmux new -s hybrid
python Transfer_Pareto_Hybrid.py
# Ctrl+B, D
```

**Instance 4: Adapter**
```bash
tmux new -s adapter
python Transfer_Pareto_Adapter.py
# Ctrl+B, D
```

### 3.3 tmux ëª…ë ¹ì–´

```bash
# ì„¸ì…˜ ì¬ì ‘ì†
tmux attach -t prompt

# ì„¸ì…˜ ëª©ë¡ í™•ì¸
tmux ls

# ì„¸ì…˜ ì¢…ë£Œ (ì¬ì ‘ì† í›„)
exit

# detach (Ctrl+B, D)
```

---

## 4. ëª¨ë‹ˆí„°ë§

### 4.1 ë¡œì»¬ì—ì„œ WandB ëª¨ë‹ˆí„°ë§

**í”„ë¡œì íŠ¸ë³„ í™•ì¸:**
- Prompt: `DNN_channel_estimation_InH_Prompt_Pareto` (ì™¸ 4ê°œ)
- LoRA: `DNN_channel_estimation_InH_LoRA_Pareto` (ì™¸ 4ê°œ)
- Hybrid: `DNN_channel_estimation_InH_Hybrid_Pareto` (ì™¸ 4ê°œ)
- Adapter: `DNN_channel_estimation_InH_Adapter_Pareto` (ì™¸ 4ê°œ)

ì´ 20ê°œ í”„ë¡œì íŠ¸ (4 methods Ã— 5 scenarios)

### 4.2 ì¸ìŠ¤í„´ìŠ¤ ì§ì ‘ í™•ì¸

```bash
# SSH ì¬ì ‘ì†
ssh root@X.X.X.X -p XXXXX

# tmux ì„¸ì…˜ í™•ì¸
tmux attach -t prompt

# GPU ì‚¬ìš©ë¥  í™•ì¸
nvidia-smi

# ë¡œê·¸ í™•ì¸ (ì¶œë ¥ ìŠ¤í¬ë¡¤)
# tmux ì•ˆì—ì„œ Ctrl+B, [ í›„ ë°©í–¥í‚¤
```

### 4.3 ì˜ˆìƒ ì†Œìš” ì‹œê°„

| Method | Runs | Time/Run | Total Time |
|--------|------|----------|------------|
| Prompt | 15 | 2-4h | 30-60h |
| LoRA | 20 | 2-4h | 40-80h |
| Hybrid | 15 | 2-4h | 30-60h |
| Adapter | 20 | 2-4h | 40-80h |

**ë³‘ë ¬ ì‹¤í–‰ ì‹œ**: ìµœëŒ€ 40-80ì‹œê°„ (LoRA/Adapter ê¸°ì¤€)

---

## 5. ê²°ê³¼ ìˆ˜ì§‘

### 5.1 ê° ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ê²°ê³¼ ì••ì¶•

```bash
cd /workspace/DNN_channel_estimation_training

# Prompt ê²°ê³¼
tar -czf pareto_prompt_results.tar.gz saved_model/pareto/*prompt*

# LoRA ê²°ê³¼
tar -czf pareto_lora_results.tar.gz saved_model/pareto/*lora*

# Hybrid ê²°ê³¼
tar -czf pareto_hybrid_results.tar.gz saved_model/pareto/*hybrid*

# Adapter ê²°ê³¼
tar -czf pareto_adapter_results.tar.gz saved_model/pareto/*adapter*
```

### 5.2 ë¡œì»¬ë¡œ ë‹¤ìš´ë¡œë“œ

```bash
# ë¡œì»¬ í„°ë¯¸ë„ì—ì„œ
scp -P PORT root@PROMPT_IP:/workspace/.../pareto_prompt_results.tar.gz .
scp -P PORT root@LORA_IP:/workspace/.../pareto_lora_results.tar.gz .
scp -P PORT root@HYBRID_IP:/workspace/.../pareto_hybrid_results.tar.gz .
scp -P PORT root@ADAPTER_IP:/workspace/.../pareto_adapter_results.tar.gz .
```

### 5.3 ì••ì¶• í•´ì œ ë° ì •ë¦¬

```bash
# ë¡œì»¬ì—ì„œ
tar -xzf pareto_prompt_results.tar.gz -C saved_model/pareto/
tar -xzf pareto_lora_results.tar.gz -C saved_model/pareto/
tar -xzf pareto_hybrid_results.tar.gz -C saved_model/pareto/
tar -xzf pareto_adapter_results.tar.gz -C saved_model/pareto/
```

---

## 6. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 6.1 CUDA Out of Memory

**ì¦ìƒ:**
```
RuntimeError: CUDA out of memory
```

**í•´ê²°:**
```python
# config íŒŒì¼ì—ì„œ batch_size ì¤„ì´ê¸°
batch_size: 16  # ì›ë˜ 32
```

### 6.2 ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨

**Google Drive ì§ì ‘ ë‹¤ìš´ë¡œë“œ ì œí•œ:**
```bash
# gdownì´ ì•ˆ ë˜ë©´ wget ì‚¬ìš©
wget --load-cookies /tmp/cookies.txt "https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=FILE_ID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')&id=FILE_ID" -O filename && rm -rf /tmp/cookies.txt
```

### 6.3 WandB ë¡œê·¸ì¸ ì•ˆ ë¨

```bash
# ìˆ˜ë™ ë¡œê·¸ì¸
wandb login

# ë˜ëŠ” configì—ì„œ ë¹„í™œì„±í™”
use_wandb: False
```

### 6.4 tmux ì„¸ì…˜ ëŠê¹€

```bash
# ì„¸ì…˜ í™•ì¸
tmux ls

# ì¬ì ‘ì†
tmux attach -t prompt

# ì„¸ì…˜ì´ ì—†ìœ¼ë©´ ë‹¤ì‹œ ì‹œì‘
python Transfer_Pareto_Prompt.py
```

### 6.5 ë””ìŠ¤í¬ ìš©ëŸ‰ ë¶€ì¡±

```bash
# ìš©ëŸ‰ í™•ì¸
df -h

# ë¶ˆí•„ìš”í•œ íŒŒì¼ ì‚­ì œ
rm -rf /workspace/.cache
rm -rf /tmp/*

# ì²´í¬í¬ì¸íŠ¸ë§Œ ë‚¨ê¸°ê³  ì‚­ì œ (ì™„ë£Œ í›„)
cd saved_model/pareto
rm *_iter_*.pt  # ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ
```

---

## 7. ë¹„ìš© ì ˆê° íŒ

### 7.1 Interruptible ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
- On-demandë³´ë‹¤ 50-70% ì €ë ´
- ì¤‘ë‹¨ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ checkpoint ì €ì¥ í•„ìˆ˜

### 7.2 ì™„ë£Œ ì¦‰ì‹œ ì¢…ë£Œ
```bash
# ìŠ¤í¬ë¦½íŠ¸ ë§ˆì§€ë§‰ì— ìë™ ì¢…ë£Œ ì¶”ê°€
echo "shutdown -h now" >> run_script.sh
```

### 7.3 ì €ë ´í•œ GPU ì„ íƒ
- RTX 3090: $0.2-0.4/hour
- í•„í„°: "DLPerf > 80" + "Reliability > 0.95"

---

## 8. ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì‹¤í–‰ ì „
- [ ] GitHubì— ì½”ë“œ í‘¸ì‹œ ì™„ë£Œ
- [ ] Google Driveì— ëª¨ë¸ íŒŒì¼ ì—…ë¡œë“œ
- [ ] WandB API key ì¤€ë¹„
- [ ] Vast.ai ê³„ì •ì— í¬ë ˆë”§ ì¶©ì „

### ê° ì¸ìŠ¤í„´ìŠ¤ë§ˆë‹¤
- [ ] SSH ì ‘ì† í™•ì¸
- [ ] ì½”ë“œ í´ë¡  ì™„ë£Œ
- [ ] ì˜ì¡´ì„± ì„¤ì¹˜ ì™„ë£Œ
- [ ] ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ
- [ ] CUDA ì‘ë™ í™•ì¸
- [ ] tmux ì„¸ì…˜ì—ì„œ ì‹¤í–‰ ì‹œì‘
- [ ] WandBì—ì„œ ë¡œê·¸ í™•ì¸

### ì™„ë£Œ í›„
- [ ] 4ê°œ ì‹¤í—˜ ëª¨ë‘ ì™„ë£Œ í™•ì¸
- [ ] ê²°ê³¼ íŒŒì¼ ì••ì¶•
- [ ] ë¡œì»¬ë¡œ ë‹¤ìš´ë¡œë“œ
- [ ] ì¸ìŠ¤í„´ìŠ¤ ì¢…ë£Œ (ë¹„ìš© ì ˆê°)
- [ ] WandB ë¡œê·¸ ë°±ì—…

---

## 9. ì°¸ê³  ëª…ë ¹ì–´ ëª¨ìŒ

```bash
# ì‹œìŠ¤í…œ ì •ë³´
nvidia-smi
df -h
free -h
top

# Python í™˜ê²½
python --version
pip list | grep torch
pip list | grep peft

# Git
git pull
git status

# tmux
tmux new -s NAME
tmux attach -t NAME
tmux ls
tmux kill-session -t NAME

# íŒŒì¼ ì „ì†¡
scp -P PORT local_file root@IP:/workspace/
scp -P PORT root@IP:/workspace/file local_path/

# ì••ì¶•
tar -czf archive.tar.gz folder/
tar -xzf archive.tar.gz
```

---

## 10. ì˜ˆìƒ ê²°ê³¼

### 10.1 íŒŒì¼ êµ¬ì¡°
```
saved_model/pareto/
â”œâ”€â”€ Large_estimator_v4_to_InH_prompt_len50.pt
â”œâ”€â”€ Large_estimator_v4_to_InH_prompt_len50_iter_20000.pt
â”œâ”€â”€ ... (ì´ 420ê°œ íŒŒì¼: 70 final + 350 checkpoints)
```

### 10.2 WandB í”„ë¡œì íŠ¸
- ì´ 20ê°œ í”„ë¡œì íŠ¸ (4 methods Ã— 5 scenarios)
- ê° í”„ë¡œì íŠ¸ë‹¹ 3-4ê°œ run
- ì´ 70ê°œ runs

---

**ë‹¤ìŒ ë‹¨ê³„**: [PARETO_EXPERIMENT_DESIGN.md](PARETO_EXPERIMENT_DESIGN.md) ì°¸ì¡°
