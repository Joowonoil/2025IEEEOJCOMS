# Vast.ai ë³‘ë ¬ ì‹¤í–‰ ê°€ì´ë“œ (ê°„ì†Œí™” ë²„ì „)

Pareto Frontier ì‹¤í—˜ì„ 4ê°œì˜ Vast.ai ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ëŠ” ë°©ë²•

**ì‘ì„±ì¼**: 2025-11-02 (ìµœì¢… ì—…ë°ì´íŠ¸: 2025-11-03)
**ì˜ˆìƒ ì‹œê°„**: 35-70ì‹œê°„ (ë³‘ë ¬ ì‹¤í–‰)
**ì˜ˆìƒ ë¹„ìš©**: $60-100 (RTX 3090/4090 + ê³ ì„±ëŠ¥ CPU ê¸°ì¤€)

---

## âš ï¸ ì¤‘ìš”: ì‹¤ì „ì—ì„œ ë°°ìš´ êµí›ˆ

### CPU ì„±ëŠ¥ì´ ê°€ì¥ ì¤‘ìš”!
- **ì´ í”„ë¡œì íŠ¸ëŠ” ë°ì´í„° ë¡œë”©/ì „ì²˜ë¦¬ê°€ ë³‘ëª©** â†’ CPU ì‹±ê¸€ì½”ì–´ ì„±ëŠ¥ì´ í•µì‹¬
- GPUë§Œ ì¢‹ê³  CPUê°€ ë‚˜ì˜ë©´ ì˜¤íˆë ¤ ë¡œì»¬ë³´ë‹¤ ëŠë¦¼!

### ì¶”ì²œ CPU (í•„ìˆ˜!)
- âœ… **AMD Ryzen 7900X / 7950X** (5.4GHz+)
- âœ… AMD Ryzen 9 7900X3D / 7950X3D
- âœ… Intel Core i9-13900K / 14900K
- âŒ AMD EPYC (ì„œë²„ìš©, ëŠë¦° ì‹±ê¸€ì½”ì–´)
- âŒ ì˜¤ë˜ëœ Xeon (ëŠë¦¼)

### Config ì„¤ì •
```yaml
batch_size: 32        # ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€ (ê²°ê³¼ ì¼ê´€ì„±)
num_workers: 0        # CPU ì¢‹ìœ¼ë©´ 0ì´ ìµœì  (multiprocessing ì˜¤ë²„í—¤ë“œ ì—†ìŒ)
```

---

## ğŸ“‹ ë¹ ë¥¸ ì‹œì‘

### 1. ì¸ìŠ¤í„´ìŠ¤ ì„ íƒ (ê°€ì¥ ì¤‘ìš”!)

**Vast.ai í•„í„° ì„¤ì •:**
```
GPU: RTX 3090 / RTX 4090 (24GB)
CPU: Ryzen 7900 OR Ryzen 7950 OR i9-13900 OR i9-14900
RAM: 32GB+
Disk: 100GB+
```

**4ê°œ ì¸ìŠ¤í„´ìŠ¤ ëŒ€ì—¬:**
- Instance 1: Adapter (20 runs)
- Instance 2: LoRA (20 runs)
- Instance 3: Prompt (15 runs)
- Instance 4: Hybrid (15 runs)

---

### 2. ë°ì´í„° ì¤€ë¹„ (ë¡œì»¬ì—ì„œ í•œ ë²ˆë§Œ)

```powershell
# Windows PowerShell
cd C:\Users\YOUR_PATH\DNN_channel_estimation_training

# ì••ì¶•
Compress-Archive -Path dataset -DestinationPath dataset.zip -Force
Compress-Archive -Path saved_model -DestinationPath saved_model.zip -Force
```

---

### 3. ê° ì¸ìŠ¤í„´ìŠ¤ Setup (4ê°œ ë°˜ë³µ)

#### Step 1: SSH ì ‘ì†
```bash
ssh root@X.X.X.X -p XXXXX
```

#### Step 2: ì½”ë“œ í´ë¡ 
```bash
cd /workspace
git clone https://github.com/Joowonoil/2025IEEEOJCOMS
cd 2025IEEEOJCOMS
```

#### Step 3: íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
pip install -r requirements_vastai.txt
```

#### Step 4: CUDA í™•ì¸
```bash
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}'); print(f'Device: {torch.cuda.get_device_name(0)}')"
```

#### Step 5: ë°ì´í„° ì—…ë¡œë“œ

**Jupyter Lab ì‚¬ìš© (ê°€ì¥ í™•ì‹¤!):**

1. Vast.ai â†’ Jupyter Lab ì—´ê¸°
2. ì¢Œì¸¡ íŒŒì¼ ë¸Œë¼ìš°ì € â†’ Upload ë²„íŠ¼ (â†‘)
3. `dataset.zip`, `saved_model.zip` ì—…ë¡œë“œ (10-30ë¶„)
4. í„°ë¯¸ë„ì—ì„œ ì••ì¶• í•´ì œ:

```bash
cd /workspace/2025IEEEOJCOMS
unzip dataset.zip
unzip saved_model.zip

# í™•ì¸
ls dataset/PDP_processed/*.mat | head -5
ls saved_model/Large_estimator_v3_base_extended_final.pt
ls saved_model/Large_estimator_v4_base_extended_final.pt
```

#### Step 6: WandB ë¡œê·¸ì¸
```bash
wandb login YOUR_API_KEY
```

#### Step 7: Config í™•ì¸
```bash
# num_workersê°€ 0ì¸ì§€ í™•ì¸ (ì¤‘ìš”!)
grep -E "batch_size|num_workers" config/config_pareto_adapter.yaml
# ì¶œë ¥: batch_size: 32, num_workers: 0
```

#### Step 8: ì‹¤í–‰
```bash
# Instance 1 (Adapter)
nohup python Transfer_Pareto_Adapter.py > adapter.log 2>&1 &

# Instance 2 (LoRA)
nohup python Transfer_Pareto_LoRA.py > lora.log 2>&1 &

# Instance 3 (Prompt)
nohup python Transfer_Pareto_Prompt.py > prompt.log 2>&1 &

# Instance 4 (Hybrid)
nohup python Transfer_Pareto_Hybrid.py > hybrid.log 2>&1 &
```

#### Step 9: ëª¨ë‹ˆí„°ë§
```bash
# ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸
tail -f adapter.log  # (ë˜ëŠ” lora.log, prompt.log, hybrid.log)

# GPU ì‚¬ìš©ë¥  í™•ì¸ (ë³„ë„ í„°ë¯¸ë„)
watch -n 1 nvidia-smi

# Ctrl+Cë¡œ ì¢…ë£Œí•´ë„ ì‹¤í—˜ì€ ê³„ì† ì‹¤í–‰ë¨
```

---

## ğŸ” ëª¨ë‹ˆí„°ë§

### GPU Utilization í™•ì¸
```bash
nvidia-smi
```

**ì •ìƒ ìƒíƒœ:**
- GPU Utilization: 50-90%
- Memory-Usage: 2-5GB (batch_size=32 ê¸°ì¤€)
- Power: 100-200W

**ë¹„ì •ìƒ ìƒíƒœ (CPU ë³‘ëª©):**
- GPU Utilization: 0-10%
- Memory-Usage: ì‚¬ìš© ì¤‘ì´ì§€ë§Œ idle
- â†’ **CPUë¥¼ ë” ì¢‹ì€ ê²ƒìœ¼ë¡œ êµì²´!**

### WandB í™•ì¸
- Adapter: `DNN_channel_estimation_*_Adapter_Pareto` (5ê°œ ì‹œë‚˜ë¦¬ì˜¤)
- LoRA: `DNN_channel_estimation_*_LoRA_Pareto` (5ê°œ ì‹œë‚˜ë¦¬ì˜¤)
- Prompt: `DNN_channel_estimation_*_Prompt_Pareto` (5ê°œ ì‹œë‚˜ë¦¬ì˜¤)
- Hybrid: `DNN_channel_estimation_*_Hybrid_Pareto` (5ê°œ ì‹œë‚˜ë¦¬ì˜¤)

ì´ 20ê°œ í”„ë¡œì íŠ¸, 70ê°œ runs

---

## ğŸ“¥ ê²°ê³¼ ìˆ˜ì§‘

### ê° ì¸ìŠ¤í„´ìŠ¤ì—ì„œ:
```bash
cd /workspace/2025IEEEOJCOMS

# ê²°ê³¼ ì••ì¶•
tar -czf pareto_adapter_results.tar.gz saved_model/pareto/*adapter*
# (ë˜ëŠ” lora, prompt, hybrid)
```

### ë¡œì»¬ë¡œ ë‹¤ìš´ë¡œë“œ:
```bash
# ë¡œì»¬ í„°ë¯¸ë„
scp -P PORT root@IP:/workspace/2025IEEEOJCOMS/pareto_adapter_results.tar.gz .
```

### ì••ì¶• í•´ì œ:
```bash
tar -xzf pareto_adapter_results.tar.gz -C saved_model/pareto/
```

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. í•™ìŠµì´ ëŠë¦¼ (ê°€ì¥ í”í•œ ë¬¸ì œ!)

**ì¦ìƒ:** nvidia-smiì—ì„œ GPU Utilization 0-10%

**ì›ì¸:** CPU ì„±ëŠ¥ ë¶€ì¡± (ë°ì´í„° ë¡œë”© ë³‘ëª©)

**í•´ê²°:**
```bash
# CPU í™•ì¸
lscpu | grep "Model name"

# CPUê°€ EPYC, ì˜¤ë˜ëœ Xeonì´ë©´ ì¸ìŠ¤í„´ìŠ¤ êµì²´!
# Ryzen 7900X / 7950X / i9-13900K ì´ìƒìœ¼ë¡œ êµì²´
```

### 2. CUDA Out of Memory

**ì¦ìƒ:**
```
RuntimeError: CUDA out of memory
```

**í•´ê²°:**
```bash
# config íŒŒì¼ ìˆ˜ì • (ê²°ê³¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ ì£¼ì˜!)
nano config/config_pareto_adapter.yaml
# batch_size: 32 â†’ 16
```

### 3. í”„ë¡œì„¸ìŠ¤ í™•ì¸/ì¢…ë£Œ

**í”„ë¡œì„¸ìŠ¤ í™•ì¸:**
```bash
ps aux | grep Transfer_Pareto
```

**ì¢…ë£Œ:**
```bash
pkill -f Transfer_Pareto_Adapter.py
# ë˜ëŠ”
kill <PID>
```

### 4. ë””ìŠ¤í¬ ìš©ëŸ‰ ë¶€ì¡±

**í™•ì¸:**
```bash
df -h
```

**ì •ë¦¬:**
```bash
rm -rf /workspace/.cache
rm -rf /tmp/*
```

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì¸ìŠ¤í„´ìŠ¤ ëŒ€ì—¬ ì‹œ
- [ ] CPU: Ryzen 7900X/7950X ë˜ëŠ” i9-13900K ì´ìƒ
- [ ] GPU: RTX 3090 / 4090 (24GB)
- [ ] RAM: 32GB+
- [ ] Disk: 100GB+

### ê° ì¸ìŠ¤í„´ìŠ¤ Setup
- [ ] ì½”ë“œ í´ë¡ 
- [ ] requirements_vastai.txt ì„¤ì¹˜
- [ ] CUDA ì‘ë™ í™•ì¸
- [ ] dataset + saved_model ì—…ë¡œë“œ & ì••ì¶• í•´ì œ
- [ ] WandB ë¡œê·¸ì¸
- [ ] config í™•ì¸ (batch_size: 32, num_workers: 0)
- [ ] nohup ì‹¤í–‰
- [ ] nvidia-smi GPU ì‚¬ìš© í™•ì¸ (50-90%)

### ì™„ë£Œ í›„
- [ ] 4ê°œ ì‹¤í—˜ ëª¨ë‘ ì™„ë£Œ
- [ ] ê²°ê³¼ ì••ì¶• & ë‹¤ìš´ë¡œë“œ
- [ ] ì¸ìŠ¤í„´ìŠ¤ ì¢…ë£Œ (ë¹„ìš© ì ˆê°!)
- [ ] WandB ë¡œê·¸ í™•ì¸

---

## ğŸ’¡ ì¶”ê°€ íŒ

### ë¹„ìš© ì ˆê°
- **Interruptible ì¸ìŠ¤í„´ìŠ¤**: 50-70% ì €ë ´í•˜ì§€ë§Œ ì¤‘ë‹¨ë  ìˆ˜ ìˆìŒ
- checkpoint ì €ì¥ ê°„ê²© í™•ì¸: `model_save_step: 20000`

### ë°ì´í„° ì¬ì‚¬ìš©
- ì²« ë²ˆì§¸ ì¸ìŠ¤í„´ìŠ¤ì—ì„œ dataset.zip, saved_model.zip ë‹¤ìš´ë¡œë“œ
- ë‚˜ë¨¸ì§€ ì¸ìŠ¤í„´ìŠ¤ì— ì¬ì—…ë¡œë“œ (ì‹œê°„ ì ˆì•½)

### ë™ì‹œ ì‘ì—…
- 4ê°œ í„°ë¯¸ë„ ì—´ì–´ì„œ ë™ì‹œì— setupí•˜ë©´ ë¹ ë¦„
- Jupyter Labì€ ì—¬ëŸ¬ íƒ­ì—ì„œ ë™ì‹œ ì—…ë¡œë“œ ê°€ëŠ¥

---

## ğŸ“Š ì˜ˆìƒ ê²°ê³¼

**íŒŒì¼ ê°œìˆ˜:**
- Adapter: 20 final + 100 checkpoints = 120ê°œ
- LoRA: 20 final + 100 checkpoints = 120ê°œ
- Prompt: 15 final + 75 checkpoints = 90ê°œ
- Hybrid: 15 final + 75 checkpoints = 90ê°œ
- **ì´ 420ê°œ íŒŒì¼**

**WandB Runs:**
- ì´ 70ê°œ runs (4 methods Ã— 5 scenarios Ã— 3-4 configs)

---

## ğŸš¨ ì•Œë ¤ì§„ ì´ìŠˆ

### torch_tensorrt ì—ëŸ¬ (ì´ë¯¸ í•´ê²°ë¨)
- `ModuleNotFoundError: No module named 'torch_tensorrt'`
- â†’ estimator_v3.py, estimator_v4.pyì—ì„œ import ì œê±°ë¨
- â†’ `git pull`ë¡œ ìµœì‹  ì½”ë“œ ë°›ìœ¼ë©´ í•´ê²°

### Google Drive gdown ì‹¤íŒ¨
- ê¶Œí•œ ë¬¸ì œë¡œ ì‹¤íŒ¨ ê°€ëŠ¥ì„± ë†’ìŒ
- â†’ **Jupyter Lab ì—…ë¡œë“œ ì‚¬ìš© ê¶Œì¥**

### Windows multiprocessing ì—ëŸ¬
- `num_workers > 0`ì´ë©´ pickle ì—ëŸ¬ ë°œìƒ
- â†’ Vast.ai(Linux)ì—ì„œëŠ” ë¬¸ì œ ì—†ìŒ
- â†’ í•˜ì§€ë§Œ `num_workers: 0`ì´ ë” ë¹ ë¦„ (CPU ì¢‹ìœ¼ë©´)

---

**ë‹¤ìŒ ë‹¨ê³„**: [PARETO_EXPERIMENT_DESIGN.md](PARETO_EXPERIMENT_DESIGN.md) ì°¸ì¡°
